---
title: "ANÁLISIS ESTADÍSTICO PRODUCCIÓN MAÍZ"
author: 
  - JHON SEBASTIAN VALENCIA URBANO - 2456780
  - JHON JAIRO PANTOJA ALVAREZ - 2355
  - JAIME ANDRES OSPINA - 2456
output: 
  rmdformats::readthedown:
    toc_depth: 5
    number_sections: true
    css: styles.css
    highlight: "pygments"
favicon: "LOGO.png"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

### **Resumen**

En este informe se documenta el viaje de transformar un conjunto de datos brutos de las Evaluaciones Agropecuarias Municipales (EVA) en inteligencia de negocio para una empresa agrícola líder. El objetivo es caracterizar la producción de Maíz, estandarizando la información y corrigiendo inconsistencias para construir una base sólida que permita identificar los departamentos más productivos, detectar anomalías significativas y descubrir las tendencias que definirán las estrategias futuras de la compañía.
***

### **Introducción**

Una importante empresa agrícola nacional, con un vasto portafolio de cultivos, se encuentra en una encrucijada estratégica. Para fortalecer su liderazgo en el mercado, necesita optimizar su operación de maíz, un pilar fundamental de su negocio. La dirección ha planteado preguntas clave: ¿En qué regiones debemos invertir? ¿Dónde se encuentran nuestras operaciones más eficientes? ¿Qué lecciones nos ha dejado la última década?

Para responder, se nos ha entregado una base de datos histórica, consolidada por un equipo anterior. Sin embargo, este activo digital presenta un desafío inicial: datos desorganizados, inconsistencias y vacíos de información. Nuestra misión como equipo de análisis de datos es embarcarnos en un viaje para convertir este caos en claridad, realizando un preprocesamiento exhaustivo para forjar una herramienta de análisis fiable y, finalmente, hacer que los datos cuenten la historia de la producción de maíz en Colombia.

### **Preparación de la Data: Forjando la Herramienta**

Todo gran análisis comienza con datos de alta calidad. Esta primera fase es la más crítica: es donde transformamos la materia prima —un conjunto de datos crudo y desordenado— en una base de datos limpia, coherente y lista para ser interrogada. Es el equivalente a afinar los instrumentos antes de un concierto.

#### **Carga de Librerías y Segmentación del Cultivo**

Nuestra historia comienza con un universo de información sobre toda la producción agrícola de la empresa. Para encontrar las respuestas sobre el maíz, nuestro primer paso es enfocar el lente, aislando la señal de nuestro cultivo de interés del ruido generado por los demás.

*Explicación del código:Se cargan las librerías que nos acompañarán en este viaje analítico. Luego, se leen los datos y, mediante filter(), se segmenta el dataframe para crear una nueva base de datos que contiene exclusivamente los registros de MAÍZ*
```{r message=FALSE, warning=FALSE, results='hide'}
library(dplyr);library(stringr);library(ggplot2);library(tidyverse);
library(patchwork);library(tidyr);library(naniar);library(corrplot)
library(mice);library(plotly);library(readxl);library(table1)

datos <- readxl::read_excel("C:/Users/johnn/Desktop/GESTION DE DATOS/TALLER PREPROCESAMIENTO/DATOS/eva_df_2025.xlsx")
level_CULTIVO <- c(MAIZ = "MAIZ", maiz = "MAIZ")
datos <- datos %>% mutate(CULTIVO = recode(CULTIVO, !!!level_CULTIVO))
datos <- datos %>% filter(CULTIVO == "MAIZ")
```
#### **Carga de Librerías y Segmentación del Cultivo**

Los nombres de las columnas originales son poco intuitivos, lo que puede llevar a errores. Para trabajar de manera eficiente y clara, debemos establecer un lenguaje común.

**Explicación del código:**
*Se define un vector con nombres claros y estandarizados, y se asigna directamente a las columnas del dataframe datos. Ahora, todos en el equipo sabemos exactamente a qué se refiere cada variable.*
```{r message=TRUE,results='hide'}
nuevos_nombres <- c("departamento", "municipio", "grupo", "cultivo", "ano",
                    "area_sembrada", "area_cosechada", "t_produccion",
                    "estado_fisico", "ciclo_cultivo")
names(datos) <- nuevos_nombres
```


#### **Creación de la Variable Rendimiento**

Producir mucho no es sinónimo de ser eficiente. La empresa necesita una métrica que mida la productividad por hectárea. Aquí es donde creamos al protagonista de nuestro análisis: la variable rendimiento.

**Explicación del código:**
*Usando 'mutate()', creamos la columna rendimiento. La fórmula t_produccion / area_cosechada se implementa con case_when() para manejar de forma robusta casos especiales, como divisiones por cero o datos faltantes, asegurando la calidad de nuestro indicador clave.*

```{r message=TRUE,results='hide'}
  datos <- datos %>%
  mutate(
    rendimiento = case_when(
      is.na(t_produccion) | is.na(area_cosechada) ~ NA_real_,
      area_cosechada == 0 ~ 0,
      TRUE ~ t_produccion / area_cosechada
    )
  )
```


#### **Tareas Adicionales de Preprocesamiento**

Los datos, como cualquier recurso, pueden tener impurezas. Para garantizar la integridad técnica y la fiabilidad de nuestras conclusiones, realizamos una limpieza final.
**Explicación del código:**
*Primero, estandarizamos los nombres de los departamentos a mayúsculas para asegurar que 'Valle' y 'VALLE' se traten como uno solo. Segundo, en lugar de descartar filas con información faltante (lo que podría sesgar nuestros resultados), optamos por un método de imputación estadística (mice) para rellenar los vacíos de forma inteligente. El resultado es Datos_ImputR, nuestro set de datos final: completo, limpio y confiable.*

```{r message=TRUE,results='hide'}
library(dplyr)
# 1. Estandarizar texto a mayúsculas
datos <- datos %>% 
  mutate(departamento = str_to_upper(departamento))

# 2. Imputación de datos faltantes
imputR <- mice(datos, m = 5, maxit = 5, seed = 123, print = F) 
Datos_ImputR <- complete(imputR)
```

### **Procesamiento de Datos: Extrayendo las Respuestas**

Con nuestra herramienta de datos ya forjada y afinada, comienza la fase de exploración. Ahora podemos interrogar a los datos para que nos revelen sus secretos y nos guíen hacia decisiones de negocio más inteligentes.

#### **Distribución de la muestra por departamentos**
Antes de analizar el rendimiento, necesitamos mapear el terreno: ¿de dónde proviene nuestra información? Este mapa nos muestra la concentración de datos a nivel nacional.

```{r echo=FALSE}
#obtencion de frecuencia en la muestra
datos_freq <- Datos_ImputR %>%
  count(departamento)

#grafico de distribucion de muestra
plot_ly(datos_freq, labels = ~departamento, values = ~n, type = "pie") %>%
  layout(title = list(text = "<b>DISTRIBUCIÓN DE LA MUESTRA POR DEPARTAMENTOS</b>",
      font = list(color = "darkred",  size = 15),x = 0.5, xanchor = "center"))
```

